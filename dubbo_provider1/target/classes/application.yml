server:
  port: 8001

spring:
  application:
    name: dubbo-auto-configuration-provider-demo

  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: test
      enable-auto-commit: true
      auto-commit-interval: 1000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # kafka offset机制：存储当前消费分区的偏移量，即使挂了或者再均衡问题引发重新分配partation,也能从正确的位置继续消费
      # latest: 有提交的offset时，从提交的offset开始，无提交的offset时，消费新产生的数据
      # earlist： 有提交的offset时，从提交的offset开始，无提交的offset时，从头开始消费
      # none:  有提交的offset时，从提交的offset开始，存在一个未提交的offset的分区时，抛出异常
      auto-offset-reset: latest


dubbo:
  application:
    name: ${spring.application.name}
  scan:
    base-packages: com.cygao.dubbo_provider1.service

  protocol:
    name: dubbo
    port: 12345

  registry:
    address: zookeeper://127.0.0.1:2181?client=curator
